{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogCI_Ki5xeDa",
    "outputId": "b89c18b4-61d9-44ad-fc42-e6c133584976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Hellooo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/content/drive/My Drive/Network Science Project/cleaned_airports.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "routes_file_path = '/content/drive/My Drive/Network Science Project/cleaned_routes.csv'\n",
    "routes_df = pd.read_csv(routes_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UxS0pdx0xpEM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "# Create a new graph object\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Add nodes based on airport data\n",
    "for index, row in df.iterrows():\n",
    "    graph.add_node(row['IATA'],\n",
    "                   name=row['Name'],\n",
    "                   city=row['City'],\n",
    "                   country=row['Country'],\n",
    "                   latitude=row['Latitude'],\n",
    "                   longitude=row['Longitude'])\n",
    "\n",
    "# Add edges based on routes data\n",
    "for index, row in routes_df.iterrows():\n",
    "    source_airport = row['Source']\n",
    "    destination_airport = row['Destination']\n",
    "    # Check if both airports exist in the graph's nodes\n",
    "    if source_airport in graph.nodes and destination_airport in graph.nodes:\n",
    "        graph.add_edge(source_airport, destination_airport, airline=row['Airline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBgmWIrQ4cUM"
   },
   "source": [
    "# Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoiyKnmSzeOa",
    "outputId": "d666ac21-592c-482d-889f-fbb9cfde329e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LCC size: 3231\n",
      "Robustness (High Degree Removal): 92\n",
      "Robustness (Low Degree Removal): 3231\n",
      "Robustness (Random Removal): 2791\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def test_robustness(graph, removal_strategy, fraction_to_remove):\n",
    "    \"\"\"\n",
    "    Tests network robustness by removing nodes/edges.\n",
    "\n",
    "    Args:\n",
    "        graph: The networkx graph object.\n",
    "        removal_strategy: 'high_degree', 'low_degree', 'random'.\n",
    "        fraction_to_remove: Fraction of nodes/edges to remove.\n",
    "\n",
    "    Returns:\n",
    "        The size of the largest connected component after removal.\n",
    "    \"\"\"\n",
    "    graph_copy = graph.copy()  # Create a copy to avoid modifying the original graph\n",
    "    num_to_remove = int(len(graph_copy) * fraction_to_remove)\n",
    "\n",
    "    if removal_strategy == 'high_degree':\n",
    "        nodes_to_remove = sorted(graph_copy.degree, key=lambda item: item[1], reverse=True)[:num_to_remove]\n",
    "        nodes_to_remove = [node[0] for node in nodes_to_remove]\n",
    "        graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    elif removal_strategy == 'low_degree':\n",
    "        nodes_to_remove = sorted(graph_copy.degree, key=lambda item: item[1])[:num_to_remove]\n",
    "        nodes_to_remove = [node[0] for node in nodes_to_remove]\n",
    "        graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    elif removal_strategy == 'random':\n",
    "        nodes_to_remove = random.sample(list(graph_copy.nodes()), num_to_remove)\n",
    "        graph_copy.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Calculate largest connected component size\n",
    "    largest_cc = max(nx.connected_components(graph_copy), key=len)\n",
    "    return len(largest_cc)\n",
    "\n",
    "# usage\n",
    "fraction_removed = 0.1  # Remove 10% of nodes\n",
    "robustness_high_degree = test_robustness(graph, 'high_degree', fraction_removed)\n",
    "robustness_low_degree = test_robustness(graph, 'low_degree', fraction_removed)\n",
    "robustness_random = test_robustness(graph, 'random', fraction_removed)\n",
    "\n",
    "# Calculate baseline LCC before removal\n",
    "baseline_lcc_size = len(max(nx.connected_components(graph), key=len))\n",
    "\n",
    "\n",
    "print(f\"Baseline LCC size: {baseline_lcc_size}\")\n",
    "print(f\"Robustness (High Degree Removal): {robustness_high_degree}\")\n",
    "print(f\"Robustness (Low Degree Removal): {robustness_low_degree}\")\n",
    "print(f\"Robustness (Random Removal): {robustness_random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnWL2WMg4WkU"
   },
   "source": [
    "# Delay Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7X3Y0w4F03Iz",
    "outputId": "c9c16d66-083f-4bd4-80d2-77d0c528dc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Delayed Airport: JFK, Degree: 162\n",
      " Delayed Airport: ORD, Degree: 206\n",
      "\n",
      "Number of airports experiencing delays: 3223\n",
      "Percentage of airports experiencing delays: 53.07%\n",
      "\n",
      "Average delay: 49.33 minutes\n",
      "\n",
      "Airport Delays:\n",
      "Airport with minimum delay: Hornafjörður Airport (46 minutes)\n",
      "Airport with maximum delay: Goroka Airport (50 minutes)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def simulate_delay_propagation(graph, initial_delay_airports, delay_duration):\n",
    "    \"\"\"Simulates delay propagation in the network.\"\"\"\n",
    "    # Initialize delay dictionary\n",
    "    delays = {airport: 0 for airport in graph.nodes()}\n",
    "\n",
    "    # Introduce initial delays\n",
    "    for airport in initial_delay_airports:\n",
    "        delays[airport] = delay_duration\n",
    "\n",
    "    # Simulate delay propagation for a fixed number of steps\n",
    "    for _ in range(10):  # Adjust the number of steps as needed\n",
    "        for airport in graph.nodes():\n",
    "            if delays[airport] > 0:\n",
    "                # Spread delay to neighbors\n",
    "                for neighbor in graph.neighbors(airport):\n",
    "                    # Assume delay propagation with some probability\n",
    "                    if random.random() < 0.5:  # Adjust probability as needed\n",
    "                        delays[neighbor] = max(delays[neighbor], delays[airport] - 1)  # Delay decreases over time\n",
    "                delays[airport] -= 1  # Delay at current airport decreases\n",
    "\n",
    "    return delays\n",
    "\n",
    "# usage\n",
    "initial_delay_airports = ['JFK', 'ORD']  # Replace with actual airport codes\n",
    "delay_duration = 60  # Initial delay in minutes\n",
    "final_delays = simulate_delay_propagation(graph, initial_delay_airports, delay_duration)\n",
    "\n",
    "# Print degree of airports with initial delay\n",
    "for airport in initial_delay_airports:\n",
    "    degree = graph.degree(airport)\n",
    "    print(f\" Delayed Airport: {airport}, Degree: {degree}\")\n",
    "\n",
    "# Calculate number and percentage of airports with delays\n",
    "delayed_airports = [airport for airport, delay in final_delays.items() if delay > 0]\n",
    "num_delayed_airports = len(delayed_airports)\n",
    "total_airports = len(graph.nodes())\n",
    "percentage_delayed = (num_delayed_airports / total_airports) * 100\n",
    "\n",
    "print(f\"\\nNumber of airports experiencing delays: {num_delayed_airports}\")\n",
    "print(f\"Percentage of airports experiencing delays: {percentage_delayed:.2f}%\")\n",
    "\n",
    "# Calculate average, min, and max delay\n",
    "delays_list = [delay for delay in final_delays.values() if delay > 0]  # Exclude 0 delays\n",
    "average_delay = sum(delays_list) / len(delays_list) if delays_list else 0  # Handle empty list\n",
    "min_delay = min(delays_list) if delays_list else 0\n",
    "max_delay = max(delays_list) if delays_list else 0\n",
    "\n",
    "print(f\"\\nAverage delay: {average_delay:.2f} minutes\")\n",
    "# Print delays with full airport names\n",
    "print(\"\\nAirport Delays:\")\n",
    "# Find airport with minimum delay\n",
    "min_delay_airport = min(final_delays, key=final_delays.get) if delays_list else None\n",
    "if min_delay_airport:\n",
    "    min_delay_airport_name = next((node_data['name'] for node, node_data in graph.nodes(data=True) if node == min_delay_airport), min_delay_airport)\n",
    "    print(f\"Airport with minimum delay: {min_delay_airport_name} ({min_delay} minutes)\")\n",
    "\n",
    "# Find airport with maximum delay\n",
    "max_delay_airport = max(final_delays, key=final_delays.get) if delays_list else None\n",
    "if max_delay_airport:\n",
    "    max_delay_airport_name = next((node_data['name'] for node, node_data in graph.nodes(data=True) if node == max_delay_airport), max_delay_airport)\n",
    "    print(f\"Airport with maximum delay: {max_delay_airport_name} ({max_delay} minutes)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg1EII5N3pDl",
    "outputId": "edfe7b1d-6e9a-49fd-8b97-4ff6582863f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 airports causing the most delays:\n",
      "1. Istanbul Airport: 26.25 minutes\n",
      "2. McCarran International Airport: 26.25 minutes\n",
      "3. Northwest Arkansas Regional Airport: 26.25 minutes\n",
      "4. Rajiv Gandhi International Airport: 26.24 minutes\n",
      "5. Provo Municipal Airport: 26.24 minutes\n"
     ]
    }
   ],
   "source": [
    "def find_critical_airports(graph, delay_duration):\n",
    "    \"\"\"Finds the top airports causing the most delays.\"\"\"\n",
    "    airport_delays = {}  # Store average delays for each airport\n",
    "\n",
    "    for airport in graph.nodes():\n",
    "        # Simulate delay propagation with a delay at the current airport\n",
    "        final_delays = simulate_delay_propagation(graph, [airport], delay_duration)\n",
    "\n",
    "        # Calculate average delay across all airports\n",
    "        total_delay = sum(final_delays.values())\n",
    "        avg_delay = total_delay / len(graph.nodes())\n",
    "\n",
    "        # Store average delay for this airport\n",
    "        airport_delays[airport] = avg_delay\n",
    "\n",
    "    # Rank airports by average delay (descending)\n",
    "    ranked_airports = sorted(airport_delays.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    return ranked_airports\n",
    "\n",
    "delay_duration = 60  # Initial delay in minutes\n",
    "ranked_airports = find_critical_airports(graph, delay_duration)\n",
    "\n",
    "print(\"Top 5 airports causing the most delays:\")\n",
    "for i in range(min(5, len(ranked_airports))):  # Print up to 5 airports\n",
    "    airport, avg_delay = ranked_airports[i]\n",
    "    airport_name = next((node_data['name'] for node, node_data in graph.nodes(data=True) if node == airport), airport)\n",
    "    print(f\"{i + 1}. {airport_name}: {avg_delay:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLPUqRGB68dN"
   },
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FwqlmLN7GHP",
    "outputId": "923f8d71-b6bb-4866-d9b8-628de2d8f5ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 critical nodes:\n",
      "1. Frankfurt am Main Airport\n",
      "2. Amsterdam Airport Schiphol\n",
      "3. Charles de Gaulle International Airport\n",
      "4. London Heathrow Airport\n",
      "5. Munich Airport\n",
      "6. Istanbul Airport\n",
      "7. Leonardo da Vinci–Fiumicino Airport\n",
      "8. Dubai International Airport\n",
      "9. Adolfo Suárez Madrid–Barajas Airport\n",
      "10. Zürich Airport\n"
     ]
    }
   ],
   "source": [
    "def rank_nodes_by_centrality(graph, weight='weight'):\n",
    "    \"\"\"Ranks nodes by combined centrality metrics.\"\"\"\n",
    "    # Calculate centrality metrics\n",
    "    degree_centrality = nx.degree_centrality(graph)\n",
    "    betweenness_centrality = nx.betweenness_centrality(graph, weight=weight)\n",
    "    closeness_centrality = nx.closeness_centrality(graph)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(graph, weight=weight)\n",
    "\n",
    "    # Combine centrality metrics (We can adjust weights but i think this is the best)\n",
    "    combined_centrality = {}\n",
    "    for node in graph.nodes():\n",
    "        combined_centrality[node] = (\n",
    "            0.25 * degree_centrality[node] +\n",
    "            0.25 * betweenness_centrality[node] +\n",
    "            0.25 * closeness_centrality[node] +\n",
    "            0.25 * eigenvector_centrality[node]\n",
    "        )\n",
    "\n",
    "    # Rank nodes by combined centrality (descending)\n",
    "    ranked_nodes = sorted(combined_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    return ranked_nodes\n",
    "\n",
    "ranked_nodes = rank_nodes_by_centrality(graph)\n",
    "\n",
    "print(\"Top 10 critical nodes:\")\n",
    "for i in range(10):\n",
    "    node, centrality = ranked_nodes[i]\n",
    "    node_data = graph.nodes[node]\n",
    "\n",
    "    print(f\"{i + 1}. {node_data['name']}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
